---
title: AI 실습 특강
author: 윤지선
date: 2026-01-07
category: TIL/윤지선/2026/01
layout: post
---

### 오늘 배운 것
## 자연어 처리

### 토큰화 방식 비교:

- 단어 : 직관적이지만 한계 명확
- 문자 : OOV 문제는 해결되지만 비효율적
- 서브워드 ( 현재의 표준 ) : jumping → jump+##ing=jumping

하지만 한국어 토큰화는 어렵다. 

→ 단어와 조사의 끝없는 결합인 ‘교착어’ 특성 때문

→ 해결 방안: 한국어 특화 토큰화 3대 전략

1. 형태소 분석 기반 토큰화
2. 통계 기반 서브워드 토큰화
3. 자소 단위 토큰화

### BART (Biderectional and Auto-Regressive Transformers)

- BART는 양방향 transformer encoder와 자기회귀 디코더를 결합한 Seq2Seq 모델임

### ROUGE 지표

- Rouge-1은 unigram, 단어 하나
- Rouge-2는 bigram, 단어 두 개
- Rouge-L은 Longest Common Subsequence

### 전이 학습(Transfer Learning)

- 이미 만들어진 거대 모델을 활용해 시간, 비용, 데이터를 획기적으로 절약함
- 적은 양의 데이터, 저비용으로 높은 성능을 보임

---

### 내일 할 일
경제 IT 기사 스크랩, AI 특강 실습 진행하기

---
### 참고자료
