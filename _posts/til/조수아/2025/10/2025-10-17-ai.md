---
title: 2025-10-17
author: 조수아
date: 2025-10-17
category: TIL/조수아/2025/10
layout: post
---

# 오늘 배운 것

# 교차검증 (Cross-Validation)

## 1️⃣ 테스트 성능 평가 (Model Evaluation)

### ✅ 훈련 오류 vs 테스트 오류
- **훈련 오류 (Training Error)**  
  모델을 학습시킨 **같은 데이터**에 적용해 계산한 오류
- **테스트 오류 (Test Error)**  
  학습에 **사용하지 않은 새로운 데이터**로 계산한 예측 오류

> ⚠️ 훈련 오류는 일반적으로 테스트 오류보다 **낮게 측정**됨  
> → 즉, **과적합(overfitting)** 가능성 존재

📌 **비유:**  
훈련 오류는 ‘암기 시험’,  
테스트 오류는 ‘응용 시험’에 가깝다.

## 2️⃣ 검증셋 접근 (Validation Set Approach)

### 2-1. 검증셋(Validation Set) 방법
- 전체 데이터를 무작위로 **훈련셋**과 **검증셋(hold-out)** 으로 분할
- 훈련셋으로 모델을 학습하고, 검증셋으로 예측하여 오류 계산
- **평가 지표**
  - 회귀: MSE (Mean Squared Error)
  - 분류: 오분류율, F1-score 등

### 2-2. 절차
1. 데이터를 무작위로 셔플링  
2. 훈련셋(파랑) / 검증셋(주황)으로 분할  
3. 훈련셋으로 모델 학습  
4. 검증셋으로 성능 평가

### 2-3. 예시
> 데이터의 일부만으로 모델을 학습하고, 남은 부분으로 검증을 수행

### 2-4. 한계점
- **검증 결과의 변동성 높음**  
  → 어떤 샘플이 검증셋에 포함되느냐에 따라 결과가 크게 달라짐  
- **테스트 오류 과대 추정 경향**  
  → 전체 데이터로 학습하지 않기 때문에 모델 성능이 실제보다 낮게 나올 수 있음  

## 3️⃣ K-겹 교차검증 (K-fold Cross-Validation)

### 3-1. 개념
- 데이터를 **K개의 동일 크기 폴드(fold)** 로 나눈 뒤,  
  각 폴드를 검증셋으로 번갈아 사용하며 나머지는 훈련에 사용
- 모든 폴드에 대해 테스트를 반복 후, **평균 오류**로 최종 테스트 오류 추정

📌 **과정**
1. 데이터를 무작위로 섞는다 (shuffle)
2. 데이터를 K개의 폴드로 분할
3. 각 폴드가 한 번씩 검증셋이 되도록 K회 반복
4. 각 회차의 오류(MSE 등)를 평균하여 테스트 오류 추정

### 3-2. 수식적 표현
\[
\text{CV Error} = \frac{1}{K} \sum_{k=1}^{K} MSE_k
\]
> 각 폴드의 검증 오류를 평균하여 모델의 일반화 성능을 추정한다.

## 4️⃣ Leave-One-Out 교차검증 (LOOCV)

- **검증셋 크기:** 1개 관측치
- **훈련셋:** 나머지 n−1개 데이터
- **과정:**  
  n개의 데이터 각각을 검증셋으로 사용해 n번 반복 → 평균 MSE 계산

📌 장점  
- 데이터 낭비 없음  
- 훈련 데이터 최대 활용

📌 단점  
- 연산량이 많음 (n번 모델 학습 필요)

## 5️⃣ K-겹 교차검증 비교

| 구분 | 장점 | 단점 |
|------|------|------|
| **Validation Set** | 구현 간단, 빠름 | 데이터 낭비, 결과 변동성 큼 |
| **K-fold CV** | 효율적, 데이터 낭비 적음 | K번 모델 학습 필요 (비용 증가) |
| **Leave-One-Out** | 데이터 최대 활용 | 계산량 매우 큼 |

> 일반적으로 **10-겹 교차검증 (K=10)** 이 많이 사용됨.  
> → bias와 variance의 균형이 잘 맞기 때문.

## 🔍 핵심 요약

- 교차검증은 **데이터 낭비 없이 일반화 오류를 추정**하는 방법
- 검증셋 접근은 간단하지만, **데이터 부족** 및 **결과 불안정**이 문제
- K-겹 교차검증은 **표준적 접근법**으로 가장 많이 사용됨
- Leave-One-Out은 이론적으로는 정밀하나 **실용성은 낮음**