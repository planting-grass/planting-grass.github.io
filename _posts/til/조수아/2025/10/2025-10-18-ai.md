---
title: 2025-10-18
author: 조수아
date: 2025-10-18
category: TIL/조수아/2025/10
layout: post
---

# 오늘 배운 것

# 비지도 학습과 클러스터링

## 1) 비지도 학습( Unsupervised Learning )

- **정의**: 라벨 없이 데이터의 구조/패턴/집단을 학습하는 방법
- **목표**: 예측이 아니라 **구조 발견 / 요약 / 표현(embedding)**
- **대표 과제**:
    - 클러스터링(Clustering)
    - 차원축소(PCA)
    - 이상치 탐지 / 밀도추정
- **핵심 질문**
    - 무엇을 “비슷함/다름” 으로 볼 것인가 → 거리/유사도 정의
    - 전처리를 어떻게 할 것인가 → 스케일링 여부 결정

---

## 2) 클러스터링(Clustering)

- 데이터 안의 **동질적인 하위 집단**(cluster)을 찾는 작업
- 목표:
    - **클러스터 내부는 유사**
    - **클러스터 간은 상이**
- 예: 마케팅 고객 세분화, 사용자 행동 그룹화

### 대표 기법

| 기법 | 특징 |
| --- | --- |
| K-means | K(군집 수)를 미리 정하고 분할 |
| 계층적 군집 | K를 사전 지정하지 않음 (덴드로그램 제공) |

---

## 3) K-means 클러스터링

- **아이디어**: 클러스터 내부 변동(Within-Cluster Variation) 합을 최소화
- **알고리즘 흐름**
    1. 무작위로 각 데이터에 1..K 할당
    2. 반복
        - (a) 각 클러스터 중심(centroid) 갱신
        - (b) 각 데이터를 가장 가까운 중심에 재할당
- **특징**
    - 매 반복마다 내부변동 감소하지만 **전역 최소 보장 X**
    - **초기값에 따라 다른 해**로 수렴 가능

---

## 4) 계층적 군집(Hierarchical Clustering)

- K 사전 고정 없이 전체 구조를 트리형(덴드로그램)으로 표현
- 강의에서는 **상향식 방식(Agglomerative)** 다룸
- **링크(link) 방식에 따라 결과 달라짐**
    - Single: 최소 거리 기반
    - Complete: 최대 거리 기반
    - Average: 평균 거리 기반

---

## 5) 클러스터링 시 주의점

- **스케일링 필요 여부** (단위 차이 영향 큼 → 표준화 추천)
- **K 선택 문제** (정답 없음 → 여러 시도 필요)
- 한 번의 결과에 집착 X — 다양한 조건/파라미터 비교 권장