---
title: 2025-10-16
author: 조수아
date: 2025-10-16
category: TIL/조수아/2025/10
layout: post
---

# 오늘 배운 것

# 지도학습(Supervised Learning)의 개념과 구성

**학습일자:** 2025.10.13

**주제:** AI & 기계학습 기초 (2) — 지도학습이란 무엇인가?

**출처:** 「AI & 기계학습 기초 2 - 지도학습은 무엇인가」
AI__기계학습_기초_2_-_지도학습은_무엇인가

---

## 1️⃣ 지도학습의 개념

### ● 정의

- **지도학습(Supervised Learning)** 은 입력(특성, Feature)과 정답(라벨, Label)이 쌍으로 주어지는 데이터를 기반으로 학습한다.
- 목표는 **새로운 입력에 대해 올바른 정답을 예측할 수 있는 규칙을 학습하는 것.**

### ● 지도학습의 두 가지 유형

| 구분 | 예측값 형태 | 예시 |
| --- | --- | --- |
| **회귀(Regression)** | 연속적인 수치 | 가격, 점수, 온도 |
| **분류(Classification)** | 범주형 값 | 스팸/정상, 질병 유무 |

---

## 2️⃣ 주요 용어

| 용어 | 설명 | 예시 |
| --- | --- | --- |
| **Feature (x)** | 예측에 사용되는 설명 변수 | {지역, 평수, 방수, 연식} |
| **Label (y)** | 모델이 맞춰야 하는 정답 | {집값, 스팸 여부} |
| **Prediction (ŷ)** | 모델이 출력한 예측값 | 예측된 가격 |
| **Error (E)** | 실제값과 예측값의 차이 | ŷ - y |

---

## 3️⃣ 회귀(Regression)

### ● 회귀 문제란?

> 입력으로부터 숫자형 결과를 예측하는 문제.
> 
> 
> 예) 광고비(입력) → 매출액(출력)
> 

### ● 평균제곱오차(MSE)

MSE=1n∑(yi−yi^)2MSE = \frac{1}{n} \sum (y_i - \hat{y_i})^2

MSE=n1∑(yi−yi^)2

- 큰 오차에 더 큰 패널티를 주는 오류 측정 방식
- 단위가 커서 비교가 어려울 때는 **RMSE (제곱근 MSE)** 사용

### ● 결정계수(R²)

- 라벨의 분산 중 **모델이 설명할 수 있는 비율**
- 0~1 사이의 값으로 표현 (1에 가까울수록 좋음)
- 단, 예측값이 평균값보다도 못하면 **R² < 0** 가능

---

## 4️⃣ 분류(Classification)

### ● 개념

> 입력으로부터 범주형 결과를 분류하는 문제.
> 
> 
> 예) 메일 내용/보낸이 → 스팸 or 정상
> 

### ● 정확도(Accuracy)

Accuracy=맞춘 데이터전체 데이터Accuracy = \frac{맞춘\ 데이터}{전체\ 데이터}

Accuracy=전체 데이터맞춘 데이터

- 단점: **불균형 데이터**에서는 신뢰하기 어려움
    - 예: 양성 1%, 음성 99%일 때 → 전부 음성으로 예측해도 99% 정확도

### ● 혼동행렬(Confusion Matrix)

| 실제\예측 | 양성 | 음성 |
| --- | --- | --- |
| **양성** | TP (정탐) | FN (누락) |
| **음성** | FP (오탐) | TN (정음) |
- **정밀도 (Precision)** = TP / (TP + FP)
- **재현율 (Recall)** = TP / (TP + FN)
- **F1-score** = 2 × (Precision × Recall) / (Precision + Recall)

---

## 5️⃣ 학습의 목적: 일반화 (Generalization)

- **모델의 성능은 새로운 데이터(테스트 데이터)에서 평가해야 함.**
- 학습 데이터에서만 성능이 좋다면 실전에서는 실패할 수 있음.
- 즉, **“훈련 오류 ↓ + 테스트 오류 ↓”** 를 동시에 목표로 해야 함.

---

## 6️⃣ 오버피팅(Overfitting)과 언더피팅(Underfitting)

| 구분 | 원인 | 증상 | 해결책 |
| --- | --- | --- | --- |
| **오버피팅** | 모델이 너무 복잡함 | 훈련 오류 ↓, 테스트 오류 ↑ | 데이터 확장, 교차검증, 정규화 |
| **언더피팅** | 모델이 너무 단순함 | 훈련/테스트 오류 모두 높음 | 모델 복잡도 증가, 학습 강화 |
- **오버피팅 오해:** 분포 변화(distribution shift)로 인한 성능 저하는 오버피팅과 다름.
    
    (예: 환경 변화, 계절, 센서 교체 등)