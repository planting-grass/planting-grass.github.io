---
title: Hadoop
author: 김희원
date: 2026-02-23
category: TIL/김희원/2026/02
layout: post
---

# Hadoop 

## 데이터 타입
- 정형 데이터: RDB, CSV
- 비정형 데이터: video, image, voice, word 
- 반정형 데이터: xml, html, json 

### 핵심 원칙 
1. Failure Tolerance 결함 허용
   - 일부 HW나 SW에 장애가 발생해도 전체 시스템 중단 안되고 서비스 계속 유지하는 거 
  - HOW? 
    - heartbeat 체크
    - 관리자 NameNode -> 작업용 노드 DataNode: 주기적으로 신호를 주고 받으면서 상태를 확인한다. 특정 서버가 응답하지 않으면 하둡은 즉시 해당 서버를 '고장'으로 간주 -> 다른 서버가 대신 일하게 한다. 
2. Load Balancing 부하 분산 
   - 특정 서버에 작업이나 데이터가 몰리지 않도록 전체 클러스터에 골고루 나누어 효율을 극대화
    - 분산: [저장] 큰 파일을 블록 단위 (기본 128MB)로 쪼개서 여러 서버에 나눠 저장한다. [처리] 여러 대의 서버가 동시에 병렬로 계산 MapReduce하기 때문에 처리 속도가 비약적으로 빨라짐
    - 회복력: 특정 서버의 과부하 또는 장애 발생 -> 다른 여유 있는 서버로 재배치 또는 복구함
3. Data Loss
   - 수백 대의 서버 중 하나만 고장 나도 데이터 유실 방지
   - HOW? 
     - Replication 복제 기법 
     - 하둡 파일 시스템(HDFS)에 데이터를 저장하면, 기본적으로 3개의 복사본(Replication Factor = 3)를 만듦. 
     - 한 두대가 고장나도 다른 서버에 복제본이 남아있어서 데이터 손실 없이 안전하게 복구할 수 있음 
  
## 하둡의 핵심 모듈 4가지 
1. hadoop common 
2. HDFS Hadoop Distributed File System 
3. Map/Reduce - Distributed Data Processing Framework 
4. Yarn - Resource Manager and Scheduler 

### HDFS란
1. 핵심 구조 Master-Slave 구조 
   - NameNode 관리자/ 마스터 
     - 파일 시스템의 메타 데이터 저장 
     - DB에서의 클러스터 인덱스에서 인덱스로 생각해도 된다 
   - DataNode 일꾼/ 슬레이브 
     - 실제 데이터를 저장하고 있는 블록 
     - 주기적으로 NameNode에게 heartbeat 신호를 전송함 
2. 동작 방식 - 어떻게 대용량 데이터를 안전하게 다룰까? 
   1. 블록 단위 저장
      1. 아주 큰 파일 -> 128MB 기본값 단위로 쪼개서 저장  
   2. 데이터 복제 
      1. 각 블록을 기본적으로 3개의 복사본 생성 -> 서로 다른 DataNode에 분산 저장 
      2. Data Loss 방지: 하나가 고장나도 복제본 있어서 괜찮음  
      3. Rack Awareness: 복제본 중 하나는 다른 Rack에 저장 -> 강제종료 돼도 데이터 지켜짐 
   3. 장애 복구 
      1. NameNode는 Datanode로부터 heartbeat가 안 오면 장애로 판단함 
      2. 항상 전체 시스템 내에 복제본 개수(기본 3개)가 유지되도록 한다. 

### Map Reduce란 
2단계 프로세스 

1. Map 모으기 
   1. 입력 데이터 -> (Key, Value)
   2. (Apple, 1), (Banana, 1), (Apple, 1) ...
2. Shuffle & Sort 중간 다리 
   1. 같은 Key를 가진 데이터 -> 모아서 정렬 
   2. Apple: [1, 1], Banana: [1]
3. Reduce 하나로 합치기 
   1. 같은 key로 묶인 데이터 -> 집계해서 결과 산출 
   2. (Apple, 2), (Banana, 1)
 
> 한계 
> - 매 단계 결과를 디스크에 쓴다. 
> - 해결책: 메모리 위에서 모든 걸 처리하는 Apache Spark 더 많이 사용함 

### YARN이란 

구성요소 
1. ResourceManager  마스터 
2. NodeManager 슬레이브
3. ApplicationMaster 
4. Container 

## 하둡 1버전 
- SPOF 문제 존재 (name node)
    - 네임 노드가 1갠데 얘가 죽으면 메타데이터가 날라가서 노드를 다 날림


## 하둡 2버전 
### 1. 하둡의 고가용성 
- Active Namenode, Standby Namenode 고가용성 가능
- 각 네임노드는 메타데이터 변화를 감지하여 로그를 기록하여 변화를 공유

✅ 어떻게 구현하는가? -> RACK 랙
- 데이터 센터에서 다수의 서버, 저장 장치, 네트워크 스위치를 효율적으로 배치하기 위해 만든 표준 규격의 철제 선반(캐비닛)
- 단, 전원 공급 장치나 스위치가 고장 나면 랙 전체의 서버가 한꺼번에 다운
- 목적: 레플리카를 위해 존재하는 녀석 
  - 3개가 있다고 하는데 물리적으로 2:1로 나눠서 저장함
  - 이 노드들을 묶어 저장하는 공간을 Rack이라고 부른다
  - 논리적으로는 3개, 물리적으로는 2개

✅ 어떤 식으로 복제하는가? 
1. **첫 번째 복제본:** 로컬 노드(데이터를 업로드하는 서버)에 저장합니다.
2. **두 번째 복제본:** **다른 랙(Remote Rack)**에 있는 노드에 저장합니다.
3. **세 번째 복제본:** 두 번째 복제본과 **같은 랙**에 있는 또 다른 노드에 저장합니다.


✅ 목적 
- **효율성:** 3개를 모두 다른 랙에 두면 네트워크 비용이 너무 큽니다. 2개를 같은 랙에 두어 데이터 전송 속도를 높입니다.
- **안전성:** 랙 하나가 통째로 고장 나도, 다른 랙에 첫 번째 복제본이 살아있기 때문에 서비스가 중단되지 않습니다.

✅ 랙은 레플리카가 아닙니다. 
- **레플리카(Replica):** 데이터의 **'복사본'** 그 자체입니다.
- **랙(Rack):** 서버들이 모여 있는 **'물리적 구역'**입니다.
- 하둡은 **레플리카**를 **랙** 단위로 분산하여 배치함으로써 **장애 내성(Fault Tolerance)**을 극대화하는 것입니다.

### 2. 하둡의 수평 확장 기능

1. **동기화:** Active와 Standby 네임노드는 **JournalNode**를 매개체로 메타데이터를 동기화하며 고가용성을 유지합니다.
2. **Namespace:** 하둡 파일 시스템의 **디렉토리 구조와 파일 메타데이터** 자체를 의미합니다.
3. **Block Pool:** (HDFS 연합 환경에서) **특정 네임노드가 관리하는 블록들의 덩어리**입니다.