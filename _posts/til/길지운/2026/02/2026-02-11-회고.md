---
title: 2026-02-11
author: 길지운
date: 2026-02-11
category: TIL/길지운/2026/02
layout: post
---

### 1일 1아티클
#### ITWORLD
###### 대규모 트래픽 대응 분산 시스템 설계 원칙
**문제 상황**
- 대형 이벤트의 인프라 운영 시, **`Thundering Herd`** 문제 발생
  - 원인 : 대규모 트래픽
  - 사례 : 올림픽 때의 미디어 업계, 블프 때의 이커머스, 금융 시스템, etc.
- 엔지니어링 팀은 대부분 **`Auto-scaling`**을 해결책으로 기대
- 매우 큰 규모에서는 **`Auto-scaling`** 한계 존재
  - 반응 속도가 느림
  - 지연 시간 급증 → DB 커넥션 풀 고갈 → 500 오류 발생
  
**`NBCUniversal`이 사용하는 아키텍처 패턴**
1. 공격적인 **`Load shedding`**
  - 로드 밸런서로 들어오는 모든 요청 처리 시도 → 동시 접속이 폭증하는 이벤트 상황에 치명적
  - 비즈니스 우선순위에 따른 `Load shedding` 적용
  - `Load shedding` : 수용 가능한 범위의 사용자에 완벽한 서비스 제공, 나머지 사용자에게는 '잠시 기다려달라'는 안내 제공
  - **게이트웨이 계층에서 트래픽을 명확한 티어로 분류** : 티어1(반드시 성공해야 하는 요청), 티어2(오래된 캐시 데이터로 제공 가능한 요청), 티어3(실패해도 사용자에게 크게 드러나지 않는 요청)
2. `Bulkhead`, 블라스트 반경 격리
  - `Bulkhead` pattern : 서로 다른 의존성을 각각 분리된 스레드 풀 / 커넥션 풀로 격리 → 특정 구성 요소 장애의 시스템 전체 확산 방지
  - 엄격한 타임아웃, `Circuit Breaker` pattern : 비필수 의존성 50% 이상 실패 시, 즉시 해당 호출 중단 및 기본값 반환
  - 고처리량 서비스는, 스레드 풀 격리보다 **세마포어 격리** : 스레드 풀은 컨텍스트 스위칭 오버헤드 존재, 세마포어는 허용되는 동시 호출 수 제한 (초과 트래픽을 큐에 안 쌓고 즉시 거부)
3. 요청 병합
  - 동시에 수많은 동일 요청 → 캐싱만으로는 한계 (`Cache Stampede` 문제 : 인기있는 Cache key 만료 시, 수많은 요청이 동시에 Cache miss 감지 → 해당 데이터 재생성을 위해 결국 DB에 몰려듦)
  - `Singleflight` 요청 병합 기법 : Cache miss 발생 시, 먼저 들어온 단 1개의 요청만 DB 접근 (나머지 요청은 대기 상태로 유지)
  - `X-Fetch` 알고리즘(확률적 조기 만료) : 캐시 항목 완전 만료 시점 전에(유효할 때), 백그라운드로 데이터를 다시 가져오는 방식 → 사용자는 항상 warm cache에 접근, `Cache Stampede` 문제 사전 차단
4. 게임데이 리허설
  - 게임데이 : 실 운영 환경에서 대규모 트래픽 상황 시뮬레이션, 인위적 장애 주입
  - 앞서 적용된 기법이 정상 작동하는지 검증
  
### 오늘 배운 것
1. 회고
2. 서비스 홍보 및 사용자 데이터 수집
  - 구글 애널리틱스 활용
  - 피드백 도구 활용 (`smore`)
  
### 내일 할 일
1. 포트폴리오 작성
  
### 참고자료
- [슈퍼볼급 트래픽을 견디는 NBC유니버설의 분산 시스템 설계 원칙](https://www.itworld.co.kr/article/4128468/%ec%8a%88%ed%8d%bc%eb%b3%bc%ea%b8%89-%ed%8a%b8%eb%9e%98%ed%94%bd%ec%9d%84-%ea%b2%ac%eb%94%94%eb%8a%94-nbc%ec%9c%a0%eb%8b%88%eb%b2%84%ec%84%a4%ec%9d%98-%eb%b6%84%ec%82%b0-%ec%8b%9c%ec%8a%a4%ed%85%9c.html)