---
title: 2026-01-09
author: 길지운
date: 2026-01-09
category: TIL/길지운/2026/01
layout: post
---

### 1일 1아티클
#### 요즘IT
###### TPU (Tensor Processing Unit)
**배경**
- 구글이 설계한 tensor 처리 장치
- tensor : 수학적 표현을 차원 단위로 확장한 개념, AI 모델의 입력 데이터 및 내부 계산 값으로 다뤄지는 형태
  - 0차원 : 하나의 값
  - 1차원 : 벡터
  - 2차원 : 행렬
  - 다차원 : 이미지, 문장 등 복잡한 데이터
- 딥러닝의 학습 및 추론 과정 → tensor 간 변환을 반복하는 작업, 대규모 모델의 핵심은 tensor 간 행렬 곱 연산
  - CPU : 범용적 제어 및 다양한 연산 처리에 적합, 대규모 행렬 연산의 반복 수행에는 비효율적
  - GPU : 병렬 연산에 강점, but 그래픽 처리라는 범용 목적도 있어 한계 존재
  - TPU : **행렬 곱을 가장 효율적으로 처리**하기 위한 전용 프로세서 
  
**TPU 구조**
- tensor 연산을 위해 조립된 몇 가지 핵심 컴포넌트의 조합
- `Systolic Array` : 아주 작은 MAC 유닛 (계산기)를 바둑판처럼 배열 후, 반복적인 곱을 순차적으로 흘려보내는 구조 (컨베이어 벨트에 부품이 이동하며 조립되는 과정과 유사)
  - 장점 : 중간 계산 결과를 **메모리에 저장하고 불러오는 과정 X**
- `On-chip Memory` : 대용량 캐시 계층의 복잡한 구조 대신, 행렬 곱에 필요한 입력 데이터 및 가중치를 칩 가까이에 배치 → 데이터 이동 거리 최소화
  - 장점 : `Systolic Array`의 데이터 흐름이 외부 메모리에 거의 의존 없이 연속적 처리 가능토록 함
- `저정밀도 연산 유닛` : 모든 계산을 정확하게 처리하기보다, AI에 충분한 정확도만 확보하면서 빠르고 효율적으로 계산
  
**TPU 적용 사례**
- `JAX` : TPU 특성을 SW 차원에서 효과적으로 활용될 수 있도록 설계된 프레임워크
  - `NumPy`와 유사한 python library, 내부적으로는 TPU가 처리하기 좋은 형태로 변환되는 구조
  
**NPU, DPU**
- AI 가속 환경 구축을 위한 구성 요소
- NPU(Neural Processing Unit) : 스마트폰, 자동차, IoT 등 전력 소모 및 지연 시간 민감한 환경을 위해 설계된 가속기
  - 상대적으로 작은 모델의 빠른 실행에 초점
  - AI를 클라우드에서 사용자 가까이로 끌어오는 역할
- DPU(Data Processing Unit) : 대규모 AI 인프라에서, AI 학습 및 추론 과정에서 발생하는 방대한 데이터 이동 작업 전담
  - CPU의 기존 작업 부담 해결
  - GPU와 TPU가 연산에만 집중할 수 있도록 돕는 역할
- 결론 : AI가 넓은 환경으로 확산 → 역할 분담의 필요로 인해 나타난 기술들
  
### 오늘 배운 것
1. AI 공용 명세서
2. 아이디어 회의 및 취합
  
### 내일 할 일
1. 아이디어 회의 (con.)
  
### 참고자료
- [GPU 시대는 끝? 제미나이 3가 쏘아 올린 TPU의 정체](https://yozm.wishket.com/magazine/detail/3543/)