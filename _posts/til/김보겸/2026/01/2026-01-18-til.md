---
title: 2026-01-18
author: 김보겸
date: 2026-01-18
category: TIL/김보겸/2026/01
layout: post
---

## MediaPipe란?

**MediaPipe**는 Google에서 개발한 실시간 멀티모달 인식 프레임워크로,  
카메라 입력을 기반으로 **얼굴, 손, 자세, 신체 움직임** 등을 빠르고 가볍게 추적할 수 있는 도구이다.

머신러닝 모델을 직접 학습하지 않아도,  
이미 학습된 **경량화된 파이프라인**을 통해 실시간 인식이 가능하다는 점이 가장 큰 특징이다.

---

## MediaPipe의 주요 특징

- **실시간 처리에 최적화**
  - CPU 환경에서도 안정적인 FPS 확보 가능
- **사전 학습 모델 제공**
  - 별도의 데이터 수집·학습 없이 바로 사용 가능
- **랜드마크 기반 결과 제공**
  - 좌표(x, y, z) 형태로 정밀한 포인트 추출
- **AI 사용 여부를 선택적으로 분리 가능**
  - 모델 추론이 아닌 규칙 기반 판단도 가능

---

## 주요 솔루션 종류

### 1. Face Mesh
- 얼굴의 **468개 랜드마크**를 추적
- 활용 예:
  - 눈 깜빡임 감지
  - 졸음 탐지
  - 표정 분석
  - 아바타 표정 동기화

### 2. Pose
- 전신 관절(33개 포인트) 추적
- 활용 예:
  - 자리 이탈 감지
  - 자세 분석
  - 스트레칭/운동 자세 인식

### 3. Hands
- 손의 21개 랜드마크 추적
- 활용 예:
  - 손동작 인식
  - 제스처 기반 인터랙션

---

## MediaPipe와 AI 모델(YOLO 등)의 차이

| 구분 | MediaPipe | YOLO |
|---|---|---|
| 방식 | 랜드마크 + 규칙 기반 | 객체 탐지(딥러닝) |
| 데이터 필요 | ❌ | ⭕ |
| 실시간성 | 매우 우수 | 환경 의존 |
| 정확도 튜닝 | 규칙 조정 | 재학습 필요 |
| 활용 예 | 졸음, 자세, 표정 | 사람/물체 존재 여부 |

👉 **졸음, 자리비움, 자세 판단**과 같이  
명확한 기준이 있는 경우에는 MediaPipe가 더 적합하다.

---

## 오늘 배운 핵심 포인트

- MediaPipe는 **AI 모델을 직접 학습하지 않아도** 실시간 인식이 가능하다.
- 단순 탐지(졸음, 자리비움)는 **MediaPipe 단독으로도 충분히 구현 가능**하다.
- 복잡한 분류·객체 인식이 필요할 경우에만 YOLO 같은 딥러닝 모델을 고려하면 된다.
- 규칙 기반 판단과 결합하면 **AI 의존도를 낮춘 안정적인 서비스 설계**가 가능하다.

---

## 활용 아이디어 (프로젝트 관점)

- 졸음 감지:  
  - 눈 종횡비(EAR) 기반 눈 감김 시간 측정
- 자리비움 감지:  
  - Pose 랜드마크 미검출 시간 기준 판단
- 아바타 연동:  
  - Face Mesh 랜드마크 → 표정 값 매핑

---

## 느낀 점

MediaPipe는  
“AI를 써야만 할 것 같은 문제”를 **비교적 단순한 구조로 해결할 수 있게 해주는 도구**라는 점에서 인상 깊었다.  

특히 실시간성이 중요한 서비스에서는  
무거운 모델보다 **MediaPipe + 규칙 기반 로직**이 더 현실적인 선택이 될 수 있음을 느꼈다.
